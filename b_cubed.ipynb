{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing the Multiplicity B-Cubed Clustering Metric\n",
    "\n",
    "The b-cubed clustering metric is often used to measure clustering performance. It has been demonstrated to avoid the weaknesses of other metrics for most applicatoins. See https://www.researchgate.net/profile/Julio_Gonzalo/publication/225548032_Amigo_E_Gonzalo_J_Artiles_J_et_alA_comparison_of_extrinsic_clustering_evaluation_metrics_based_on_formal_constraints_Inform_Retriev_12461-486/links/0c96052138dbb99740000000/Amigo-E-Gonzalo-J-Artiles-J-et-alA-comparison-of-extrinsic-clustering-evaluation-metrics-based-on-formal-constraints-Inform-Retriev-12461-486.pdf?_sg%5B0%5D=BVp5-cu12hNz0BrB9Jstgk_d8LpdMbhdL5uOE_ftkdtRBmpwbh6KQbF01DKGca87wgEaOkfDRYEcBayX9x2IGQ.bGbIvD_Ohtd-TcUi3gNjRvHm2oLy-qhuy9sQ7SeZRyOuZSf1zpEXmmxi5VrYR-zEzwP5d_uPAEz9nw-w_4AJNw&_sg%5B1%5D=F19xYSI3G3On97KihqlbmdQ64aGdnFyck-A7SJ-YGKAxjNnlJhI4bE5ltjIYEUCM438VJOrZ4EniRMTDSYPQA7_7yVQgbQoyxFZUbmYeSbj5.bGbIvD_Ohtd-TcUi3gNjRvHm2oLy-qhuy9sQ7SeZRyOuZSf1zpEXmmxi5VrYR-zEzwP5d_uPAEz9nw-w_4AJNw&_iepl= for a review and comparions of various clustering metrics. The implementation shown here is derived from this paper.\n",
    "\n",
    "One advantage of the b-cubed metric is that performance is reported in terms that are familiar (precision, recall and f-score) which carry intuitive meaning for scientists, engineers and developers.\n",
    "\n",
    "The explanation for computing the b-cubed precision metric is simply stated: Compute the precision score for each item in the population - the b-cubed precision is the average of the item precision scores. Similarly for recall: Compute the recall score for each item in the population - the b-cubed recall is the average of the item recall scores.\n",
    "\n",
    "The reference paper has several good examples and illustrations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categories and Clusters\n",
    "\n",
    "The standard terminology is used throughout. The term ***categories*** refers the true or reference group of items in a population. A **category list** refers to the list of population items grouped by their category. The term ***clusters*** refers to an inferred or computed grouping of population items. The b-cubed metric proposed to score how well the inferred grouping compares to the reference grouping, i.e. how well do the clusters conform to the categories.\n",
    "\n",
    "Category and cluster labels are arbitrary. They are external to the clustering problem. When a grouping identifier is needed within the b-cubed computation, a category or cluster is assigned an integer in the range \\[0..N-1\\] where N is the number of categories or clusters.\n",
    "\n",
    "Items in the population, on the other hand, require some kind of identifer. For simplicity, we assume that items have an integer identifier in the range \\[0..N-1\\] where N is the number of items in the population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Category and Cluster Lists\n",
    "\n",
    "A category or cluster is defined by the items that belong to it and is represented by a list of item identifiers (integers). A list of categories or clusters represents an entire population. In the simple case, an item belongs to one and only one category or cluster. In multiplicity case, an must belong to at least one category or cluster but may belong to multiple categories or clusters.\n",
    "\n",
    "In the code, a category cohort consists of a list of category lists and a cluster cohort consists of a list of cluster lists. Their representations are identical, i.e. a list of integer lists. The order of item identifiers within the lists and the order of the categories and clusters within the cohort is arbitrary ... only the item identifiers need to be consistent between the two cohorts.\n",
    "\n",
    "As an example, a 14 item population has the following category and cluster cohorts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "categories = [[0,1,2],[0,1,3,4],[5,6]]\n",
    "clusters = [[0,1,2,3,4],[5,6]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This population of 14 items consists of 5 categories of 5, 6, 1, 1, and 1 item(s). The inferred solution consists of 3 clusters of 4, 3, and 7 items. Again, the item and category/cluster ordering is arbitrary. It is only imporant the the item identifiers are consistant between categories and clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Implementation\n",
    "\n",
    "The implementation consists of three steps:\n",
    "\n",
    "1. compute inverse mappings for the cluster and category cohorts\n",
    "2. create intersection count matrices\n",
    "3. compute precision and recall\n",
    "\n",
    "### Step 1 - Computing the inverse mappings\n",
    "\n",
    "To create an inverse mapping we take the category(cluster) to node mapping and create a node to category (cluster) mapping. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "inverse cluster map: [{0}, {0}, {0}, {0}, {0}, {1}, {1}]\ninverse category map: [{0, 1}, {0, 1}, {0}, {1}, {1}, {2}, {2}]\n"
    }
   ],
   "source": [
    "#\n",
    "#   we first have to find out the number of items in the population\n",
    "#\n",
    "max_item = -1\n",
    "for cluster in clusters:\n",
    "    for item in cluster:\n",
    "        max_item = max(max_item, item)\n",
    "n_items = max_item+1\n",
    "\n",
    "cluster_inverse_map = [set() for _ in range(n_items)]\n",
    "for i, cluster in enumerate(clusters):\n",
    "    for item in cluster:\n",
    "        cluster_inverse_map[item].add(i)\n",
    "\n",
    "category_inverse_map = [set() for _ in range(n_items)]\n",
    "for i, category in enumerate(categories):\n",
    "    for item in category:\n",
    "        category_inverse_map[item].add(i)\n",
    "\n",
    "print('inverse cluster map:', cluster_inverse_map)\n",
    "print('inverse category map:', category_inverse_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the lists of categories (clusters) that a node belongs to is actually a *set* and not a list. This will be important in a later operation. Using sets instead of lists is not a restriction since an item can not belong to the same category of cluster more than one time.\n",
    "\n",
    "We now have a list of category (cluster) sets, one set for each item in the popluation. The next step is to determine the number of categories (clusters) each item has in common with other items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Create the Intersection Count Matrices\n",
    "\n",
    "In this step, the category (cluster) set for each item is compared to the sets of other items. The number of categories (clusters) they have in common is stored in an NxN matrix, where N is the number of items. The names of the matrices are given as C and L (cluster and category respectively) to stay in sync with the reference documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "C:\n[[1 1 1 1 1 0 0]\n [1 1 1 1 1 0 0]\n [1 1 1 1 1 0 0]\n [1 1 1 1 1 0 0]\n [1 1 1 1 1 0 0]\n [0 0 0 0 0 1 1]\n [0 0 0 0 0 1 1]] \n\nL:\n[[2 2 1 1 1 0 0]\n [2 2 1 1 1 0 0]\n [1 1 1 0 0 0 0]\n [1 1 0 1 1 0 0]\n [1 1 0 1 1 0 0]\n [0 0 0 0 0 1 1]\n [0 0 0 0 0 1 1]]\n"
    }
   ],
   "source": [
    "C = np.zeros((n_items,n_items), dtype=np.int32)\n",
    "L = np.zeros((n_items,n_items), dtype=np.int32)\n",
    "#\n",
    "#   we only populate the upper triangle of the matrices for now\n",
    "#\n",
    "for e1 in range(n_items):\n",
    "    for e2 in range(e1,n_items):\n",
    "        C[e1,e2] = len(cluster_inverse_map[e1] & cluster_inverse_map[e2])\n",
    "        L[e1,e2] = len(category_inverse_map[e1] & category_inverse_map[e2])\n",
    "#\n",
    "#   make the matrices symmetric since the intersection of (e1,e2) is the same as (e1,e2)\n",
    "#\n",
    "C = np.bitwise_or(C, C.T)\n",
    "L = np.bitwise_or(L, L.T)\n",
    "\n",
    "print('C:')\n",
    "print(C,'\\n')\n",
    "print('L:')\n",
    "print(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Compute Precision and Recall\n",
    "\n",
    "Now that we have the intersection counts, we can proceed with computing precision and recall. This involves first computing the \"Multiplicity Precision\" for each item pair (e1, e2) in the population. The formula for Multiplicy Precision and Recall is given as\n",
    "\n",
    "$$\n",
    "Multiplicity Precision = \\frac{Min(|C(e1) \\cap C(e2)|, |L(e1) \\cap L(e2)|)}{|C(e1) \\cap C(e2)}\n",
    "Multiplicity Recall = \\frac{Min(|C(e1) \\cap C(e2)|, |L(e1) \\cap L(e2)|)}{|L(e1) \\cap L(e2)}\n",
    "$$\n",
    "\n",
    "Note that the intersections have already been computed and stored in matrices $C$ and $L$.\n",
    "\n",
    "The numerator for the precision and recall computation is simply the minimum of $C$ and $L$ and the same for both computations so we compute that once. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#   We can safely ignore divide by zero exceptions and warnings since we replace those results with zeros\n",
    "#\n",
    "with np.errstate(divide='ignore', invalid='ignore'):\n",
    "    c_l_min = np.minimum.reduce([C,L])  # find minimum between category and cluster intersections\n",
    "    p = np.nan_to_num(c_l_min/C)        # compute multi-precision for (e1,e2) pairs\n",
    "    r = np.nan_to_num(c_l_min/L)        # compute multi-recall for (e1,e2) pairs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of the computation consists of\n",
    "\n",
    "- finding the average pair precision/recall score for each item; when taking these averages, it's important to only consider non-zero values, i.e. ony those elements where the category/cluster intersections are zero\n",
    "- finding the average of the item averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_e_prime_ave = np.sum(p, axis=1)/np.sum(C != 0, axis=1)    # compute multi-precision e2 averages for each e1 where C is non-zero\n",
    "p = np.average(p_e_prime_ave)                               # precision is the average of all e2 averages\n",
    "\n",
    "r_e_prime_ave = np.sum(r, axis=1)/np.sum(L != 0, axis=1)    # compute multi-recall e2 averages for each e1 where L is non-zero\n",
    "r = np.average(r_e_prime_ave)                               # recall is the average of all e2 averages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing F-Score\n",
    "The unweighted F-Score is computed from precision, P, and recall R by\n",
    "\n",
    "$$\n",
    "f score = 2\\frac{RP}{R+P}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "precision: 0.8857\trecall: 0.9429\tf_score: 0.9134\n"
    }
   ],
   "source": [
    "f_score = 2.0*r*p/(r+p)\n",
    "\n",
    "print(f'precision: {p:5.4f}\\trecall: {r:5.4f}\\tf_score: {f_score:5.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "ml-kernel",
   "display_name": "ml-kernel"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}